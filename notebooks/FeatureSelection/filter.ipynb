{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10708841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b069fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\User\\Desktop\\ML_Lesson\\Projects\\Project3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2218530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/preprocessed/preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b6ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12377 entries, 0 to 12376\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Model                        12377 non-null  float64\n",
      " 1   Year_of_Manufacture          12377 non-null  float64\n",
      " 2   Number_of_Engines            12377 non-null  float64\n",
      " 3   Capacity                     12377 non-null  float64\n",
      " 4   Range_(km)                   12377 non-null  int64  \n",
      " 5   Fuel_Consumption_(L/hour)    12377 non-null  float64\n",
      " 6   Hourly_Maintenance_Cost_($)  12377 non-null  float64\n",
      " 7   Age                          12377 non-null  float64\n",
      " 8   Sales_Region                 12377 non-null  float64\n",
      " 9   Price_($)                    12377 non-null  float64\n",
      " 10  HMC_per_person               12377 non-null  float64\n",
      " 11  Engine_Power_Factor          12377 non-null  float64\n",
      " 12  Price_per_Seat               12377 non-null  float64\n",
      " 13  Seats_per_Engine             12377 non-null  float64\n",
      " 14  Company_Popularity           12377 non-null  float64\n",
      " 15  FuelCost_Maint_Index         12377 non-null  float64\n",
      " 16  Engine_to_Capacity           12377 non-null  float64\n",
      " 17  Engine_Type_Piston           12377 non-null  float64\n",
      " 18  Engine_Type_Turbofan         12377 non-null  float64\n",
      " 19  Company_Airbus               12377 non-null  float64\n",
      " 20  Company_Boeing               12377 non-null  float64\n",
      " 21  Company_Bombardier           12377 non-null  float64\n",
      " 22  Company_Cessna               12377 non-null  float64\n",
      " 23  Age_Group_0-10               12377 non-null  float64\n",
      " 24  Age_Group_10-20              12377 non-null  float64\n",
      " 25  Age_Group_20-30              12377 non-null  float64\n",
      " 26  Age_Group_30-40              12377 non-null  float64\n",
      " 27  Age_Group_40+                12377 non-null  float64\n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7109b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2bfa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12377 entries, 0 to 12376\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Model                        12377 non-null  float64\n",
      " 1   Year_of_Manufacture          12377 non-null  float64\n",
      " 2   Number_of_Engines            12377 non-null  float64\n",
      " 3   Capacity                     12377 non-null  float64\n",
      " 4   Range_(km)                   12377 non-null  int64  \n",
      " 5   Fuel_Consumption_(L/hour)    12377 non-null  float64\n",
      " 6   Hourly_Maintenance_Cost_($)  12377 non-null  float64\n",
      " 7   Age                          12377 non-null  float64\n",
      " 8   Sales_Region                 12377 non-null  float64\n",
      " 9   Price_($)                    12377 non-null  float64\n",
      " 10  HMC_per_person               12377 non-null  float64\n",
      " 11  Engine_Power_Factor          12377 non-null  float64\n",
      " 12  Price_per_Seat               12377 non-null  float64\n",
      " 13  Seats_per_Engine             12377 non-null  float64\n",
      " 14  Company_Popularity           12377 non-null  float64\n",
      " 15  FuelCost_Maint_Index         12377 non-null  float64\n",
      " 16  Engine_to_Capacity           12377 non-null  float64\n",
      " 17  Engine_Type_Piston           12377 non-null  float64\n",
      " 18  Engine_Type_Turbofan         12377 non-null  float64\n",
      " 19  Company_Airbus               12377 non-null  float64\n",
      " 20  Company_Boeing               12377 non-null  float64\n",
      " 21  Company_Bombardier           12377 non-null  float64\n",
      " 22  Company_Cessna               12377 non-null  float64\n",
      " 23  Age_Group_0-10               12377 non-null  float64\n",
      " 24  Age_Group_10-20              12377 non-null  float64\n",
      " 25  Age_Group_20-30              12377 non-null  float64\n",
      " 26  Age_Group_30-40              12377 non-null  float64\n",
      " 27  Age_Group_40+                12377 non-null  float64\n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c48ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()['Range_(km)'].abs()\n",
    "selected_features = corr[corr >= 0.02].index.tolist()\n",
    "\n",
    "if 'Range_(km)' in selected_features:\n",
    "    selected_features.remove('Range_(km)')\n",
    "\n",
    "selected_features = selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a44776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a96f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[selected_features]  \n",
    "y = df['Range_(km)'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1dc57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d264e5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb2569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 1.0\n",
      "Linear Regression MAE: 1.2554406267041657e-10\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "lr_score = r2_score(y_test, y_pred)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred)\n",
    "lr_scores = cross_val_score(lr, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Linear Regression score: {lr_score}')\n",
    "print(f'Linear Regression MAE: {lr_mae}')\n",
    "print(\"K-Fold mean:\", lr_scores.mean())\n",
    "print(\"K-Fold std:\", lr_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85c992",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51327e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.705e+07, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.676e+07, tolerance: 2.498e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e+07, tolerance: 2.481e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso score: 0.9995640785674\n",
      "Lasso MAE: 95.76445344272928\n",
      "K-Fold mean: 0.9995432400183955\n",
      "K-Fold std: 7.5372361600688565e-06\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.641e+07, tolerance: 2.488e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.0001)\n",
    "\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_test)\n",
    "\n",
    "lasso_score = r2_score(y_test, y_pred)\n",
    "lasso_mae = mean_absolute_error(y_test, y_pred)\n",
    "lasso_scores = cross_val_score(lasso, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Lasso score: {lasso_score}')\n",
    "print(f'Lasso MAE: {lasso_mae}')\n",
    "print(\"K-Fold mean:\", lasso_scores.mean())\n",
    "print(\"K-Fold std:\", lasso_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b71aac",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge score: 0.9999844424172286\n",
      "Ridge MAE: 17.786939798392677\n",
      "K-Fold mean: 0.9999777880200162\n",
      "K-Fold std: 3.174399167223126e-07\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)\n",
    "\n",
    "ridge_score = r2_score(y_test, y_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred)\n",
    "ridge_scores = cross_val_score(ridge, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Ridge score: {ridge_score}')\n",
    "print(f'Ridge MAE: {ridge_mae}')\n",
    "print(\"K-Fold mean:\", ridge_scores.mean())\n",
    "print(\"K-Fold std:\", ridge_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1e806",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.901e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+08, tolerance: 2.498e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+08, tolerance: 2.481e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.9992461874607662\n",
      "ElasticNet MAE: 123.25399148571904\n",
      "K-Fold mean: 0.9992281285722764\n",
      "K-Fold std: 1.0429072960786385e-05\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e+08, tolerance: 2.488e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "en = ElasticNet(alpha=0.001, l1_ratio=0.9)\n",
    "\n",
    "en.fit(x_train, y_train)\n",
    "y_pred = en.predict(x_test)\n",
    "\n",
    "elastic_score = r2_score(y_test, y_pred)\n",
    "elastic_mae = mean_absolute_error(y_test, y_pred)\n",
    "elastic_scores = cross_val_score(en, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'ElasticNet score: {elastic_score}')\n",
    "print(f'ElasticNet MAE: {elastic_mae}')\n",
    "print(\"K-Fold mean:\", elastic_scores.mean())\n",
    "print(\"K-Fold std:\", elastic_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b53c4",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7684357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 1.0\n",
      "Decision Tree MAE: 0.0\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "dt_score = r2_score(y_test, y_pred)\n",
    "dt_mae = mean_absolute_error(y_test, y_pred)\n",
    "dt_scores = cross_val_score(dt, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Decision Tree score: {dt_score}')\n",
    "print(f'Decision Tree MAE: {dt_mae}')\n",
    "print(\"K-Fold mean:\", dt_scores.mean())\n",
    "print(\"K-Fold std:\", dt_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2354971",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score: 1.0\n",
      "Random Forest MAE: 0.0\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "rf_score = r2_score(y_test, y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "rf_scores = cross_val_score(rf, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Random Forest score: {rf_score}')\n",
    "print(f'Random Forest MAE: {rf_mae}')\n",
    "print(\"K-Fold mean:\", rf_scores.mean())\n",
    "print(\"K-Fold std:\", rf_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25b308",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa87503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.9999999992943458\n",
      "Gradient Boosting MAE: 0.1318368600822727\n",
      "K-Fold mean: 0.9999999992944417\n",
      "K-Fold std: 3.5424756233243284e-14\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "\n",
    "gbr_score = r2_score(y_test, y_pred)\n",
    "gbr_mae = mean_absolute_error(y_test, y_pred)\n",
    "gbr_scores = cross_val_score(gb, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Gradient Boosting score: {gbr_score}')\n",
    "print(f'Gradient Boosting MAE: {gbr_mae}')\n",
    "print(\"K-Fold mean:\", gbr_scores.mean())\n",
    "print(\"K-Fold std:\", gbr_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5da1b",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees score: 0.9999998848983022\n",
      "Extra Trees MAE: 0.03756058158319871\n",
      "K-Fold mean: 0.999999975075799\n",
      "K-Fold std: 3.524814329398763e-08\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "et = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "et.fit(x_train, y_train)\n",
    "y_pred = et.predict(x_test)\n",
    "\n",
    "et_score = r2_score(y_test, y_pred)\n",
    "et_mae = mean_absolute_error(y_test, y_pred)\n",
    "et_scores = cross_val_score(et, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Extra Trees score: {et_score}')\n",
    "print(f'Extra Trees MAE: {et_mae}')\n",
    "print(\"K-Fold mean:\", et_scores.mean())\n",
    "print(\"K-Fold std:\", et_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33dd6c6",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hist Gradient Boosting score: 0.9999999992943458\n",
      "Hist Gradient Boosting MAE: 0.1318368607055448\n",
      "K-Fold mean: 0.9999999992944417\n",
      "K-Fold std: 3.5424756233243284e-14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hgb = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "hgb.fit(x_train, y_train)\n",
    "y_pred = hgb.predict(x_test)\n",
    "\n",
    "hgb_score = r2_score(y_test, y_pred)\n",
    "hgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "hgb_scores = cross_val_score(hgb, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Hist Gradient Boosting score: {hgb_score}')\n",
    "print(f'Hist Gradient Boosting MAE: {hgb_mae}')\n",
    "print(\"K-Fold mean:\", hgb_scores.mean())\n",
    "print(\"K-Fold std:\", hgb_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3cf63",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9caa589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR score: 0.9764158300422742\n",
      "SVR MAE: 479.1067514489813\n",
      "K-Fold mean: 0.9609930088284475\n",
      "K-Fold std: 0.0013743847530013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel='rbf', C=10.0)\n",
    "\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred = svr.predict(x_test)\n",
    "\n",
    "svr_score = r2_score(y_test, y_pred)\n",
    "svr_mae = mean_absolute_error(y_test, y_pred)\n",
    "svr_scores = cross_val_score(svr, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'SVR score: {svr_score}')\n",
    "print(f'SVR MAE: {svr_mae}')\n",
    "print(\"K-Fold mean:\", svr_scores.mean())\n",
    "print(\"K-Fold std:\", svr_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cfe3e",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 1.0\n",
      "KNN MAE: 0.0\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "knn_score = r2_score(y_test, y_pred)\n",
    "knn_mae = mean_absolute_error(y_test, y_pred)\n",
    "knn_scores = cross_val_score(knn, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'KNN score: {knn_score}')\n",
    "print(f'KNN MAE: {knn_mae}')\n",
    "print(\"K-Fold mean:\", knn_scores.mean())\n",
    "print(\"K-Fold std:\", knn_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd186f20",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16192570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost score: 1.0\n",
      "XGBoost MAE: 0.0005456188227981329\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "xgb_model.fit(x_train, y_train)\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "\n",
    "xgb_score = r2_score(y_test, y_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "xgb_scores = cross_val_score(xgb_model, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'XGBoost score: {xgb_score}')\n",
    "print(f'XGBoost MAE: {xgb_mae}')\n",
    "print(\"K-Fold mean:\", xgb_scores.mean())\n",
    "print(\"K-Fold std:\", xgb_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6cbfb",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95dec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost score: 1.0\n",
      "AdaBoost MAE: 0.0\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ab = AdaBoostRegressor()\n",
    "\n",
    "ab.fit(x_train, y_train)\n",
    "y_pred = ab.predict(x_test)\n",
    "\n",
    "ab_score = r2_score(y_test, y_pred)\n",
    "ab_mae = mean_absolute_error(y_test, y_pred)\n",
    "ab_scores = cross_val_score(ab, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'AdaBoost score: {ab_score}')\n",
    "print(f'AdaBoost MAE: {ab_mae}')\n",
    "print(\"K-Fold mean:\", ab_scores.mean())\n",
    "print(\"K-Fold std:\", ab_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188cf28",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1321\n",
      "[LightGBM] [Info] Number of data points in the train set: 9901, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7798.079992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1321\n",
      "[LightGBM] [Info] Number of data points in the train set: 8251, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7792.443340\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1321\n",
      "[LightGBM] [Info] Number of data points in the train set: 8251, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7760.310265\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1321\n",
      "[LightGBM] [Info] Number of data points in the train set: 8252, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7793.875424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LGBM Regressor R2: 0.9999999992943458\n",
      "LGBM Regressor MAE: 0.1318368607055448\n",
      "K-Fold mean: 0.9999999992944417\n",
      "K-Fold std: 3.5424756233243284e-14\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_pred = lgbm.predict(x_test)\n",
    "\n",
    "lgbm_score = r2_score(y_test, y_pred)\n",
    "lgbm_mae = mean_absolute_error(y_test, y_pred)\n",
    "lgbm_scores = cross_val_score(lgbm, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(\"LGBM Regressor R2:\", lgbm_score)\n",
    "print(\"LGBM Regressor MAE:\", lgbm_mae)\n",
    "print(\"K-Fold mean:\", lgbm_scores.mean())\n",
    "print(\"K-Fold std:\", lgbm_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c05035",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa733745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor R2: 1.0\n",
      "Bagging Regressor MAE: 0.0\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Engine_Power_Factor', 'Price_per_Seat', 'Seats_per_Engine', 'Company_Popularity', 'FuelCost_Maint_Index', 'Engine_to_Capacity', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna', 'Age_Group_40+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "\n",
    "bag.fit(x_train, y_train)\n",
    "y_pred = bag.predict(x_test)\n",
    "\n",
    "bag_score = r2_score(y_test, y_pred)\n",
    "bag_mae = mean_absolute_error(y_test, y_pred)\n",
    "bag_scores = cross_val_score(bag, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(\"Bagging Regressor R2:\", bag_score)\n",
    "print(\"Bagging Regressor MAE:\", bag_mae)\n",
    "print(\"K-Fold mean:\", bag_scores.mean())\n",
    "print(\"K-Fold std:\", bag_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c675c",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor R2: 0.9999999872109224\n",
      "Voting Regressor MAE: 0.012520193902973244\n",
      "K-Fold mean R2: 0.9999999972306443\n",
      "K-Fold std R2: 3.916460348553154e-09\n",
      "Selected features: ['Capacity', 'Price_($)', 'Seats_per_Engine', 'Engine_to_Capacity']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "rf_fs = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_fs.fit(x_train, y_train)\n",
    "\n",
    "importance = rf_fs.feature_importances_\n",
    "selected_features = x_train.columns[importance > np.mean(importance)]\n",
    "\n",
    "model1 = RandomForestRegressor(random_state=42)\n",
    "model2 = ExtraTreesRegressor(random_state=42)\n",
    "model3 = LinearRegression()\n",
    "\n",
    "voting = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    ")\n",
    "\n",
    "voting.fit(x_train, y_train)\n",
    "y_pred = voting.predict(x_test)\n",
    "\n",
    "voting_score = r2_score(y_test, y_pred)\n",
    "voting_mae = mean_absolute_error(y_test, y_pred)\n",
    "voting_scores = cross_val_score(voting, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(\"Voting Regressor R2:\", voting_score)\n",
    "print(\"Voting Regressor MAE:\", voting_mae)\n",
    "print(\"K-Fold mean R2:\", voting_scores.mean())\n",
    "print(\"K-Fold std R2:\", voting_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326840f6",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66221c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor R2: 1.0\n",
      "Stacking Regressor MAE: 5.2241305878240335e-11\n",
      "K-Fold mean R2: 1.0\n",
      "K-Fold std R2: 0.0\n",
      "Selected features: ['Capacity', 'Price_($)', 'Seats_per_Engine', 'Engine_to_Capacity']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "rf_fs = RandomForestRegressor(random_state=42)\n",
    "rf_fs.fit(x_train, y_train)\n",
    "\n",
    "importance = rf_fs.feature_importances_\n",
    "selected_features = x_train.columns[importance > np.mean(importance)]\n",
    "\n",
    "base1 = RandomForestRegressor(random_state=42)\n",
    "base2 = ExtraTreesRegressor(random_state=42)\n",
    "base3 = LinearRegression()\n",
    "\n",
    "stacking = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', base1),\n",
    "        ('et', base2),\n",
    "        ('lr', base3)\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred = stacking.predict(x_test)\n",
    "\n",
    "stacking_score = r2_score(y_test, y_pred)\n",
    "stacking_mae = mean_absolute_error(y_test, y_pred)\n",
    "stacking_scores = cross_val_score(stacking, x, y,  cv=kf, scoring='r2')\n",
    "\n",
    "print(\"Stacking Regressor R2:\", stacking_score)\n",
    "print(\"Stacking Regressor MAE:\", stacking_mae)\n",
    "print(\"K-Fold mean R2:\", stacking_scores.mean())\n",
    "print(\"K-Fold std R2:\", stacking_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ea31d",
   "metadata": {},
   "source": [
    "# Bagged KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91939c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged KNN Regressor R2: 1.0\n",
      "Bagged KNN Regressor MAE: 0.0\n",
      "K-Fold mean R2: 1.0\n",
      "K-Fold std R2: 0.0\n"
     ]
    }
   ],
   "source": [
    "bag_knn = BaggingRegressor(\n",
    "    estimator=KNeighborsRegressor(),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bag_knn.fit(x_train, y_train)\n",
    "y_pred = bag_knn.predict(x_test)\n",
    "\n",
    "bag_knn_score = r2_score(y_test, y_pred)\n",
    "bag_knn_mae = mean_absolute_error(y_test, y_pred)\n",
    "bag_knn_scores = cross_val_score(bag_knn, x_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print(\"Bagged KNN Regressor R2:\", bag_knn_score)\n",
    "print(\"Bagged KNN Regressor MAE:\", bag_knn_mae)\n",
    "print(\"K-Fold mean R2:\", bag_knn_scores.mean())\n",
    "print(\"K-Fold std R2:\", bag_knn_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e0faa",
   "metadata": {},
   "source": [
    "# Bagged DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65a503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged DT Regressor R2: 1.0\n",
      "Bagged DT Regressor MAE: 0.0\n",
      "K-Fold mean R2: 1.0\n",
      "K-Fold std R2: 0.0\n"
     ]
    }
   ],
   "source": [
    "bag_dt = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bag_dt.fit(x_train, y_train)\n",
    "y_pred = bag_dt.predict(x_test)\n",
    "\n",
    "bag_dt_score = r2_score(y_test, y_pred)\n",
    "bag_dt_mae = mean_absolute_error(y_test, y_pred)\n",
    "bag_dt_scores = cross_val_score(bag_dt, x_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "print(\"Bagged DT Regressor R2:\", bag_dt_score)\n",
    "print(\"Bagged DT Regressor MAE:\", bag_dt_mae)\n",
    "print(\"K-Fold mean R2:\", bag_dt_scores.mean())\n",
    "print(\"K-Fold std R2:\", bag_dt_scores.std())\n",
    "\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79dba34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Embedded Method Comparison                              </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Algorithm              </span><span style=\"font-weight: bold\"> R2 score </span><span style=\"font-weight: bold\"> Mean Absolute Error </span><span style=\"font-weight: bold\"> K-Fold mean </span><span style=\"font-weight: bold\"> K-Fold std </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Linear Regression</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>       \n",
       "\n",
       " Decision Tree           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Random Forest           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " KNN                     1.00      0.00                 1.00         0.00       \n",
       "\n",
       " XGBoost                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " AdaBoost                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagging                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Stacking                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged KNN              1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged DT               1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Gradient Boosting       1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hist Gradient Boosting  1.00      0.13                 1.00         0.00       \n",
       "\n",
       " LGBMRegressor           1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hard Voting             1.00      0.01                 1.00         0.00       \n",
       "\n",
       " Extra Trees             1.00      0.04                 1.00         0.00       \n",
       "\n",
       " Ridge                   1.00      17.79                1.00         0.00       \n",
       "\n",
       " Lasso                   1.00      95.76                1.00         0.00       \n",
       "\n",
       " ElasticNet              1.00      123.25               1.00         0.00       \n",
       "\n",
       " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">SVR</span>                     <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.98</span>      <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">479.11</span>               <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.96</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                              Embedded Method Comparison                              \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mAlgorithm             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mR2 score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMean Absolute Error\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mLinear Regression\u001b[0m       \u001b[1;32m1.00\u001b[0m      \u001b[1;32m0.00\u001b[0m                 \u001b[1;32m1.00\u001b[0m         \u001b[1;32m0.00\u001b[0m       \n",
       "\n",
       " Decision Tree           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Random Forest           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " KNN                     1.00      0.00                 1.00         0.00       \n",
       "\n",
       " XGBoost                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " AdaBoost                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagging                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Stacking                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged KNN              1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged DT               1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Gradient Boosting       1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hist Gradient Boosting  1.00      0.13                 1.00         0.00       \n",
       "\n",
       " LGBMRegressor           1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hard Voting             1.00      0.01                 1.00         0.00       \n",
       "\n",
       " Extra Trees             1.00      0.04                 1.00         0.00       \n",
       "\n",
       " Ridge                   1.00      17.79                1.00         0.00       \n",
       "\n",
       " Lasso                   1.00      95.76                1.00         0.00       \n",
       "\n",
       " ElasticNet              1.00      123.25               1.00         0.00       \n",
       "\n",
       " \u001b[1;31mSVR\u001b[0m                     \u001b[1;31m0.98\u001b[0m      \u001b[1;31m479.11\u001b[0m               \u001b[1;31m0.96\u001b[0m         \u001b[1;31m0.00\u001b[0m       \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "results = [\n",
    "    ['Linear Regression', lr_score, lr_mae, lr_scores.mean(), lr_scores.std()],\n",
    "    ['Lasso', lasso_score, lasso_mae, lasso_scores.mean(), lasso_scores.std()],\n",
    "    ['Ridge', ridge_score, ridge_mae, ridge_scores.mean(), ridge_scores.std()],\n",
    "    ['ElasticNet', elastic_score, elastic_mae, elastic_scores.mean(), elastic_scores.std()],\n",
    "    ['Decision Tree', dt_score, dt_mae, dt_scores.mean(), dt_scores.std()],\n",
    "    ['Random Forest', rf_score, rf_mae, rf_scores.mean(), rf_scores.std()],\n",
    "    ['Gradient Boosting', gbr_score, gbr_mae, gbr_scores.mean(), gbr_scores.std()],\n",
    "    ['Extra Trees', et_score, et_mae, et_scores.mean(), et_scores.std()],\n",
    "    ['Hist Gradient Boosting', hgb_score, hgb_mae, hgb_scores.mean(), hgb_scores.std()],\n",
    "    ['SVR', svr_score, svr_mae, svr_scores.mean(), svr_scores.std()],\n",
    "    ['KNN', knn_score, knn_mae, knn_scores.mean(), knn_scores.std()],\n",
    "    ['XGBoost', xgb_score, xgb_mae, xgb_scores.mean(), xgb_scores.std()],\n",
    "    ['AdaBoost', ab_score, ab_mae, ab_scores.mean(), ab_scores.std()],\n",
    "    ['LGBMRegressor', lgbm_score, lgbm_mae, lgbm_scores.mean(), lgbm_scores.std()],\n",
    "    ['Bagging', bag_score, bag_mae, bag_scores.mean(), bag_scores.std()],\n",
    "    ['Hard Voting', voting_score, voting_mae, voting_scores.mean(), voting_scores.std()],\n",
    "    ['Stacking', stacking_score, stacking_mae, stacking_scores.mean(), stacking_scores.std()],\n",
    "    ['Bagged KNN', bag_knn_score, bag_knn_mae, bag_knn_scores.mean(), bag_knn_scores.std()],\n",
    "    ['Bagged DT', bag_dt_score, bag_dt_mae, bag_dt_scores.mean(), bag_dt_scores.std()],\n",
    "]\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[1], reverse=True)\n",
    "\n",
    "best_model = max(results, key=lambda x: x[1])\n",
    "worst_model = min(results, key=lambda x: x[1])\n",
    "\n",
    "table = Table(title=\"Embedded Method Comparison\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"R2 score\")\n",
    "table.add_column(\"Mean Absolute Error\")\n",
    "table.add_column(\"K-Fold mean\")\n",
    "table.add_column(\"K-Fold std\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, r2, mae, kmean, kstd = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{r2:.2f}[/bold green]\",\n",
    "            f\"[bold green]{mae:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd:.2f}[/bold green]\",\n",
    "        )\n",
    "    elif row == worst_model:\n",
    "        table.add_row(\n",
    "            f\"[bold red]{algo}[/bold red]\",\n",
    "            f\"[bold red]{r2:.2f}[/bold red]\",\n",
    "            f\"[bold red]{mae:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd:.2f}[/bold red]\",\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(algo, f\"{r2:.2f}\", f\"{mae:.2f}\", f\"{kmean:.2f}\", f\"{kstd:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5279d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Embedded Method Comparison                              </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Algorithm              </span><span style=\"font-weight: bold\"> R2 score </span><span style=\"font-weight: bold\"> Mean Absolute Error </span><span style=\"font-weight: bold\"> K-Fold mean </span><span style=\"font-weight: bold\"> K-Fold std </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Linear Regression</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>       \n",
       "\n",
       " Decision Tree           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Random Forest           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " KNN                     1.00      0.00                 1.00         0.00       \n",
       "\n",
       " XGBoost                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " AdaBoost                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagging                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Stacking                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged KNN              1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged DT               1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Gradient Boosting       1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hist Gradient Boosting  1.00      0.13                 1.00         0.00       \n",
       "\n",
       " LGBMRegressor           1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hard Voting             1.00      0.01                 1.00         0.00       \n",
       "\n",
       " Extra Trees             1.00      0.04                 1.00         0.00       \n",
       "\n",
       " Ridge                   1.00      17.79                1.00         0.00       \n",
       "\n",
       " Lasso                   1.00      95.76                1.00         0.00       \n",
       "\n",
       " ElasticNet              1.00      123.25               1.00         0.00       \n",
       "\n",
       " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">SVR</span>                     <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.98</span>      <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">479.11</span>               <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.96</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                              Embedded Method Comparison                              \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mAlgorithm             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mR2 score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMean Absolute Error\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mLinear Regression\u001b[0m       \u001b[1;32m1.00\u001b[0m      \u001b[1;32m0.00\u001b[0m                 \u001b[1;32m1.00\u001b[0m         \u001b[1;32m0.00\u001b[0m       \n",
       "\n",
       " Decision Tree           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Random Forest           1.00      0.00                 1.00         0.00       \n",
       "\n",
       " KNN                     1.00      0.00                 1.00         0.00       \n",
       "\n",
       " XGBoost                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " AdaBoost                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagging                 1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Stacking                1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged KNN              1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Bagged DT               1.00      0.00                 1.00         0.00       \n",
       "\n",
       " Gradient Boosting       1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hist Gradient Boosting  1.00      0.13                 1.00         0.00       \n",
       "\n",
       " LGBMRegressor           1.00      0.13                 1.00         0.00       \n",
       "\n",
       " Hard Voting             1.00      0.01                 1.00         0.00       \n",
       "\n",
       " Extra Trees             1.00      0.04                 1.00         0.00       \n",
       "\n",
       " Ridge                   1.00      17.79                1.00         0.00       \n",
       "\n",
       " Lasso                   1.00      95.76                1.00         0.00       \n",
       "\n",
       " ElasticNet              1.00      123.25               1.00         0.00       \n",
       "\n",
       " \u001b[1;31mSVR\u001b[0m                     \u001b[1;31m0.98\u001b[0m      \u001b[1;31m479.11\u001b[0m               \u001b[1;31m0.96\u001b[0m         \u001b[1;31m0.00\u001b[0m       \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/feature_selection_compare.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532de75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
