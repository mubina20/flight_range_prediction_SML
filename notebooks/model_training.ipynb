{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6745a6e4",
   "metadata": {},
   "source": [
    "# Tez va qulay holda test qilish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80f725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374da744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engineering import FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3923193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/engineered/engineered_airplane_price_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c730cfd",
   "metadata": {},
   "source": [
    "# import Algorithms / K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6feec648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba9f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e5ae0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de3bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelection(df, target=\"Range_(km)\")\n",
    "fs.filter_by_correlation()\n",
    "selected_features = fs.get_selected_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be40e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[selected_features]\n",
    "y = df['Range_(km)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a7f04",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12419893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12c970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4e2b0",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a595ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression score: 1.0\n",
      "linear regression mae: 1.357586138282928e-10\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "lr_score = r2_score(y_test, y_pred)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred)\n",
    "lr_scores = cross_val_score(lr, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'linear regression score: {lr_score}')\n",
    "print(f'linear regression mae: {lr_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", lr_scores.mean())\n",
    "print(\"K-Fold std:\", lr_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ad441",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "311e1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+08, tolerance: 2.989e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+08, tolerance: 2.983e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+08, tolerance: 2.986e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression score: 0.9995522461933098\n",
      "Lasso regression mae: 93.61488052389285\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9995433795883827\n",
      "K-Fold std: 1.4722316030991374e-05\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+08, tolerance: 2.993e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(x_test)\n",
    "\n",
    "lasso_score = r2_score(y_test, y_pred)\n",
    "lasso_mae = mean_absolute_error(y_test, y_pred)\n",
    "lasso_scores = cross_val_score(lasso, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Lasso regression score: {lasso_score}')\n",
    "print(f'Lasso regression mae: {lasso_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", lasso_scores.mean())\n",
    "print(\"K-Fold std:\", lasso_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda9c8c",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8eff33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression score: 1.0\n",
      "Ridge regression mae: 2.115012030881248e-05\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.0000001)\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(x_test)\n",
    "\n",
    "ridge_score = r2_score(y_test, y_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred)\n",
    "ridge_scores = cross_val_score(ridge, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Ridge regression score: {ridge_score}')\n",
    "print(f'Ridge regression mae: {ridge_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", ridge_scores.mean())\n",
    "print(\"K-Fold std:\", ridge_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c381b8",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3367818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+08, tolerance: 2.989e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+08, tolerance: 2.983e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+08, tolerance: 2.986e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet regression score: 0.9994246411319485\n",
      "ElasticNet regression mae: 106.14506115015706\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9994186573754045\n",
      "K-Fold std: 1.7056904338953248e-05\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+08, tolerance: 2.993e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=0.0001)\n",
    "\n",
    "elastic.fit(x_train, y_train)\n",
    "\n",
    "y_pred = elastic.predict(x_test)\n",
    "\n",
    "elastic_score = r2_score(y_test, y_pred)\n",
    "elastic_mae = mean_absolute_error(y_test, y_pred)\n",
    "elastic_scores = cross_val_score(elastic, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'ElasticNet regression score: {elastic_score}')\n",
    "print(f'ElasticNet regression mae: {elastic_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", elastic_scores.mean())\n",
    "print(\"K-Fold std:\", elastic_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe96cf",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f33e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree regression score: 1.0\n",
      "DecisionTree regression mae: 0.0\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "dt_score = r2_score(y_test, y_pred)\n",
    "dt_mae = mean_absolute_error(y_test, y_pred)\n",
    "dt_scores = cross_val_score(dt, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'DecisionTree regression score: {dt_score}')\n",
    "print(f'DecisionTree regression mae: {dt_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", dt_scores.mean())\n",
    "print(\"K-Fold std:\", dt_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c6bb9",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6661453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest regression score: 1.0\n",
      "RandomForest regression mae: 0.0\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "rf_score = r2_score(y_test, y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "rf_scores = cross_val_score(rf, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'RandomForest regression score: {rf_score}')\n",
    "print(f'RandomForest regression mae: {rf_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", rf_scores.mean())\n",
    "print(\"K-Fold std:\", rf_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41aa6a",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc426d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting regression score: 0.9999999992943458\n",
      "Gradient Boosting regression mae: 0.13183686008212356\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9999999992941238\n",
      "K-Fold std: 2.9959927334318474e-13\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gb.predict(x_test)\n",
    "\n",
    "gb_score = r2_score(y_test, y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, y_pred)\n",
    "gb_scores = cross_val_score(gb, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Gradient Boosting regression score: {gb_score}')\n",
    "print(f'Gradient Boosting regression mae: {gb_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", gb_scores.mean())\n",
    "print(\"K-Fold std:\", gb_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff81a72",
   "metadata": {},
   "source": [
    "# Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fc9ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees regression score: 0.9999981246351874\n",
      "Extra Trees regression mae: 0.15838045234248793\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9999991294656769\n",
      "K-Fold std: 1.0826455280748767e-06\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "et.fit(x_train, y_train)\n",
    "\n",
    "y_pred = et.predict(x_test)\n",
    "\n",
    "et_score = r2_score(y_test, y_pred)\n",
    "et_mae = mean_absolute_error(y_test, y_pred)\n",
    "et_scores = cross_val_score(et, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Extra Trees regression score: {et_score}')\n",
    "print(f'Extra Trees regression mae: {et_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", et_scores.mean())\n",
    "print(\"K-Fold std:\", et_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ffbd8",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "798cfba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hist Gradient Boosting score: 0.9999999992943458\n",
      "Hist Gradient Boosting mae: 0.1318368607055448\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9999999992941238\n",
      "K-Fold std: 2.9961825952557e-13\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingRegressor(random_state=42) # 200 ta daraht\n",
    "\n",
    "hgb.fit(x_train, y_train)\n",
    "y_pred = hgb.predict(x_test)\n",
    "\n",
    "hgb_score = r2_score(y_test, y_pred)\n",
    "hgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "hgb_scores = cross_val_score(hgb, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Hist Gradient Boosting score: {hgb_score}')\n",
    "print(f'Hist Gradient Boosting mae: {hgb_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", hgb_scores.mean())\n",
    "print(\"K-Fold std:\", hgb_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c22e4a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b8704e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVM score: 0.994570047227507\n",
      "CVM mae: 210.09988631530416\n",
      "--------------------------------------\n",
      "K-Fold mean: 0.9947865361292892\n",
      "K-Fold std: 0.00032251202552343504\n"
     ]
    }
   ],
   "source": [
    "svm = SVR(kernel='linear', C=20.0)\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "svm_score = r2_score(y_test, y_pred)\n",
    "svm_mae = mean_absolute_error(y_test, y_pred)\n",
    "svm_scores = cross_val_score(svm, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'CVM score: {svm_score}')\n",
    "print(f'CVM mae: {svm_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", svm_scores.mean())\n",
    "print(\"K-Fold std:\", svm_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a40966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCVM score: 0.9695048129487135\\nCVM mae: 588.2969017287465\\n--------------------------------------\\nK-Fold mean: 0.9692934000096454\\nK-Fold std: 0.0014072151252178206\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel='rbf' bulganda result:\n",
    "\n",
    "'''\n",
    "CVM score: 0.9695048129487135\n",
    "CVM mae: 588.2969017287465\n",
    "--------------------------------------\n",
    "K-Fold mean: 0.9692934000096454\n",
    "K-Fold std: 0.0014072151252178206\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7eeb46",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c6bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 1.0\n",
      "KNN mae: 0.0\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "knn_score = r2_score(y_test, y_pred)\n",
    "knn_mae = mean_absolute_error(y_test, y_pred)\n",
    "knn_scores = cross_val_score(knn, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'KNN score: {knn_score}')\n",
    "print(f'KNN mae: {knn_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", knn_scores.mean())\n",
    "print(\"K-Fold std:\", knn_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37d981",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b65d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression score: 1.0\n",
      "Lasso regression mae: 0.0005456188227981329\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor()\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "xgb_score = r2_score(y_test, y_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "xgb_scores = cross_val_score(xgb, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Lasso regression score: {xgb_score}')\n",
    "print(f'Lasso regression mae: {xgb_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", xgb_scores.mean())\n",
    "print(\"K-Fold std:\", xgb_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94f497",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4409ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression score: 1.0\n",
      "Lasso regression mae: 0.0\n",
      "--------------------------------------\n",
      "K-Fold mean: 1.0\n",
      "K-Fold std: 0.0\n",
      "Selected features: ['Model', 'Number_of_Engines', 'Capacity', 'Fuel_Consumption_(L/hour)', 'Price_($)', 'HMC_per_person', 'Cost_per_km', 'Engine_Type_Piston', 'Engine_Type_Turbofan', 'Company_Airbus', 'Company_Boeing', 'Company_Bombardier', 'Company_Cessna']\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostRegressor(n_estimators=200)\n",
    "\n",
    "ab.fit(x_train, y_train)\n",
    "y_pred = ab.predict(x_test)\n",
    "\n",
    "ab_score = r2_score(y_test, y_pred)\n",
    "ab_mae = mean_absolute_error(y_test, y_pred)\n",
    "ab_scores = cross_val_score(ab, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f'Lasso regression score: {ab_score}')\n",
    "print(f'Lasso regression mae: {ab_mae}')\n",
    "print('--------------------------------------')\n",
    "print(\"K-Fold mean:\", ab_scores.mean())\n",
    "print(\"K-Fold std:\", ab_scores.std())\n",
    "print(\"Selected features:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc87af",
   "metadata": {},
   "source": [
    "# Tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03513951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+-----------------------+\n",
      "| Algorithm              |     r2_score |   mean_absolute_error |\n",
      "+========================+==============+=======================+\n",
      "| \u001b[92mLinear Regression\u001b[0m      | \u001b[92m1.0000000000\u001b[0m |          \u001b[92m0.0000000001\u001b[0m |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Lasso                  | 0.9995522462 |         93.6148805239 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Ridge                  | 1.0000000000 |          0.0000211501 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| ElasticNet             | 0.9994246411 |          0.9994246411 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Decision Tree          | 1.0000000000 |          0.0000000000 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Random Forest          | 1.0000000000 |          0.0000000000 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Gradient Boosting      | 0.9999999993 |          0.1318368601 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Extra Trees            | 0.9999981246 |          0.1583804523 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| Hist Gradient Boosting | 0.9999999993 |          0.1318368607 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| \u001b[31mSVM\u001b[0m                    | \u001b[31m0.9945700472\u001b[0m |        \u001b[31m210.0998863153\u001b[0m |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| KNN                    | 1.0000000000 |          0.0000000000 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| XGBoost                | 1.0000000000 |          0.0005456188 |\n",
      "+------------------------+--------------+-----------------------+\n",
      "| AdoBoost               | 1.0000000000 |          0.0000000000 |\n",
      "+------------------------+--------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "result = [\n",
    "    ['Linear Regression', lr_score, lr_mae],\n",
    "    ['Lasso', lasso_score, lasso_mae],\n",
    "    ['Ridge', ridge_score, ridge_mae],\n",
    "    ['ElasticNet', elastic_score, elastic_score],\n",
    "    ['Decision Tree', dt_score, dt_mae],\n",
    "    ['Random Forest', rf_score, rf_mae],\n",
    "    ['Gradient Boosting', gb_score, gb_mae],\n",
    "    ['Extra Trees', et_score, et_mae],\n",
    "    ['Hist Gradient Boosting', hgb_score, hgb_mae],\n",
    "    ['SVM', svm_score, svm_mae],\n",
    "    ['KNN', knn_score, knn_mae],\n",
    "    ['XGBoost', xgb_score, xgb_mae],\n",
    "    ['AdoBoost', ab_score, ab_mae],\n",
    "]\n",
    "\n",
    "headers = ['Algorithm', 'r2_score', 'mean_absolute_error']\n",
    "\n",
    "best_model = max(result, key=lambda x: x[1])\n",
    "worst_model = min(result, key=lambda x: x[1])\n",
    "\n",
    "green = \"\\033[92m\"\n",
    "red = \"\\x1b[31m\"\n",
    "reset = \"\\033[0m\"\n",
    "\n",
    "for row in result:\n",
    "    if row == best_model:\n",
    "        row[:] = [green + str(i) + reset for i in row]\n",
    "    elif row == worst_model:\n",
    "        row[:] = [red + str(i) + reset for i in row]\n",
    "\n",
    "table = tabulate(result, headers=headers, tablefmt='grid', floatfmt='.10f')\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
